<!DOCTYPE html>
<head>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script type="text/javascript">
    $("document").ready(function(){
        $("#header").load("../common/headersub.html");
    });
  </script>
  <script type="text/javascript">
    $("document").ready(function(){
        $("#navigator").load("../common/navigatorsub.html");
    });
  </script>
  <script type="text/javascript">
    $("document").ready(function(){
        $("#footer").load("../common/footersub.html");
    });
  </script>
  <div id="header">

  </div>
</head>

<body>
  <div id="navigator">
  </div>

  <!-- Add all page content inside this div if you want the side nav to push page content to the right (not used if you only want the sidenav to sit on top of the page -->
  <div id="main">

<div class="column side">
  <div id="toc_container">
<p class="toc_title">Contents</p>
<ul class="toc_list">
  <li><a href="#question_1">Data</a>
  <li><a href="#question_3">Modelling</a>
  <li><a href="#question_2">Assumptions </a>
</ul>
</div>

</div>

<div class="container">


  <div class="column middle" >
    <span id="question_1">Data</span>
   <div id="content">
     Data functions

     The main uses of data for an actuary are:
     <ul>
       <li>
         setting premiums and/or contribution rates
       </li>
       <li>
         calculating reserves required to meet future liabilities
       </li>
       <li>
          preparing statutory returns to demonstrate solvency
       </li>
       <li>
         assisting with risk management decisions. e.g. determining appropriate investment, reinsurance and/or bonus distribution strategies
       </li>
       <li>
         carrying out experience analysis
         <ul>
           <li>
             to assess the suitability of past assumptions
           </li>
           <li>
             to identify unprofitable tranches of business sold in the past
           </li>
         </ul>
       </li>
     </ul>

     Data qualities
     <ul>
       <li>
         Poor quality and/or quantity of available data can have a significant adverse effect on the quality of the advice given.
       </li>
       <li>
         If data is poor quality, then results may be wrong and, if poor quantity of data, then results will have
         <span class="highlight">high degree of uncertainty</span>.
       </li>
       <li>
         Problems of data quality and quantity can be a result of:
         <ul>
           <li>
             poor management control of data recording and verification
           </li>
           <li>
             poor design of data systems
           </li>
         </ul>
       </li>
       <li>
         If possible, data used for all kinds of purposes should be controlled through one integrated data system. Data used for different purposes will be consistent, reducing possibility of errors.
       </li>
       <li>
         However, in some cases, a large quantity of high-quality past data may simply not be readily available.
       </li>
       <li>
         New company, new product, new market, new distribution channel, significant changes to terms and conditions of the product, regulatory changes (ban on gender discrimination (can use proxy instead)).
       </li>
     </ul>
     Types Sources Possible issues
     <ul>
       <li>
         Proposal form:
         <ul>
           <li>
             In both life and non-life insurance, the data gathered directly from the policyholder on the proposal form will be crucial.
           </li>
           <li>
             Questions should be clear and unambiguous. Where possible, quantitative (rather than qualitative) data should be requested.
           </li>
           <li>
             Aside from general administrative data (e.g. name, address, bank details), only measurable data likely to affect the claim amount and/or claim timing (or frequency) is required.
           </li>
           <li>
             Data collected not necessarily to price the product at this moment. But they may be used in the future.
           </li>
         </ul>
       </li>
       <li>
         Source uncontrolled by the insurer:
         <ul>
           <li>
             There are some circumstances when the actuary will not have full control over the data to be used (e.g. an actuary carrying out a statutory valuation of an occupational pension scheme).
           </li>
           <li>
             In this case, data covering the membership of the scheme and the benefits accrued by each member at the date of the valuation will usually be provided by the employer.
           </li>
           <li>
             However, where the data is provided from an external source, this is particularly important.
           </li>
           <li>
             Need to perform check on such data!
           </li>
         </ul>
       </li>
       <li>
         External source:
         <br>
         Where poor quality and/or insufficient data is available, the actuary may consider the use of data from an external source (e.g. industry-wide data, reinsurer data, national statistics).
         <br>
         This can be particularly useful to small insurance companies and companies writing a new (or specialised) class of business, where the quantity of internal data is inadequate to allow credible statistical analysis. For example, the Continuous Mortality Investigation (CMI) Bureau collects and analyses a large quantity of mortality and morbidity data from a range of life insurance companies in the UK.
         <br>
         However, the main disadvantage of external industry-wide data collection schemes is the possible distortion caused by heterogeneity between different data providers.
         <br>
         Distortions in collective data schemes can result as not all contributors will be homogeneous with regard to:
         <ul>
           <li>
             terms and conditions of policies (there must be difference !)
           </li>
           <li>
             underwriting and claim settlement practices
           </li>
           <li>
             underwriting and claim settlement practices
           </li>
           <li>
             target market
           </li>
           <li>
             nature and/or detail of data requested and stored
           </li>
         </ul>
       </li>
       <li>
         Industry-wide data also tend to be less detailed and flexible than internal data (as data will usually be provided in summarised form, with no access to underlying raw data), and more out-of date (due to time taken to collect, collate and distribute results).
       </li>
       <li>
         Life insurance: As mentioned above, the Continuous Mortality Investigation provides mortality data for both assured lives and annuitants (separated by a range of major risk factors) and also morbidity data from critical illness and income protection insurance.
         <br>
         Demographic data (such as population projections) are produced regularly by the Office of National Statistics.
       </li>
       <li>
         Non-life insurance: The Association of British Insurers also has an extensive database covering premium, claim and expense experience for the non-life insurance market as a whole (and subdivided by category covering motor, property, employersâ€™ liability etc), as well as re-insurance data for Marine, Aviation and Transport (MAT) and non-MAT business.
       </li>
     </ul>
     <li>
       Risk classification
       <ul>
         <li>
           The main aim of risk classification is to obtain homogeneous classes of data with respect to the factors affecting the risk being analysed. Then, the experience of each class will be more stable and characteristic of the underlying grouping. This allows for more accurate projection of future experience.
         </li>
         <li>
           To ensure the changes in the underlying mix of risks will not affect future experience.
         </li>
         <li>
           However, separating the data into homogeneous groupings may give insufficient data in some cells (e.g. at very low and/or very high ages). In this case, it may be necessary to combine some groupings and sacrifice some degree of homogeneity for increased credibility
         </li>
       </ul>
     </li>
     <li>
       Data verification
       <br>
       Possible checks applied to a given data set include:
       <ul>
         <li>
           reconciliation with data used at previous valuation
         </li>
         <li>
           reconciliation with accounting data
         </li>
         <li>
            any inconsistency between shareholdings at start and end of period (adjusted for sales and purchases) may indicate errors in the asset data provided
         </li>
         <li>
           checks on any unusual values in the data set
           <br>
           e.g. very high (or low) sum assured or premium may indicate individual data entry error or systematic problem

         </li>
         <li>
           random spot checks on individual data items
           <br>
           it is particularly important to check data for members (or policyholders) who have significant liabilities
         </li>

         In general, the extent of data verification in any particular situation
         will depend on the financial significance of any errors made.
       </ul>
     </li>
   </div>
  </div>


  <div class="column middle" >
    <span id="question_3">Modelling</span>
   <div id="content">
     <a href="../contract/model">The key requirements of an actuarial model</a>
     <ul>
       <li>The model being used must be valid, rigorous enough for its purpose and adequately documented
       </li>
       <li>The model chosen should be capable of adequately reflecting the risk profile of the financial products, schemes, contract or transactions being modelled.
       </li>
       <li>So at the planning stage, the requirements of all stakeholders should be brought into account and the budget/timescales/etc should be established
       </li>
       <li> At the model design stage, the methods or other models available to test the model should be considered, so that the model built can be adequately tested.
       </li>
       <li> The parameters used must allow for all those features of the business being modelled that could significantly affect the advice being given.
       </li>
       <li> The inputs to the parameter values should be appropriate to the business being modelled and take into account any special features of the provider and the economic and business environment in which it is operating.
       </li>
       <li>The workings of the model should be easy to appreciate and communicate.  This is both the structure of the model and how the parameterisation has been determined.  The model should exhibit sensible joint behaviour of model variables.
       </li>
       <li>The outputs for the model should be capable of independent verification for reasonableness. The results should be displayed clearly and should be communicable to those to whom advice will be given.
       </li>
       <li>The model must not be overly complex so that either the results become difficult to interpret and communicate or the model becomes too long or expensive to run, unless this is required by the purpose of the model.  It is important to avoid the impression that everything can be modelled.
       </li>
       <li>The model should be capable of development and refinement â€“ nothing complex can be successfully designed and built in a single attempt
       </li>
       <li>A range of methods of implementation should be available to facilitate testing, parameterisation and focus of results
       </li>
     </ul>

     Deterministic or stochastic?
     <ul>
       <li>
         Features
         <ul>
           <li>
             In a deterministic model, the parameter values are fixed at the outset and the model output will be a single realisation of the future experience.
           </li>
           <li>
             Sensitivity analysis is then used to assess the variability of the model output as a result of changing one or more parameter values.
           </li>
           <li>
             In a stochastic model, one or more of the parameters is represented by a specified probability distribution.
           </li>
           <li>
             Then, the model is run a large number of times and the value of these parameters is simulated from the chosen distribution each time. Thus, the model output will be a range of different possible future scenarios, giving an understanding of the distribution of outcomes.
           </li>
         </ul>
       </li>
       <li>
         Advantages / Disadvantages of using a stochastic model
         <ul>
           <li>
             Advantages
             <ul>
               <li>
                 allows uncertainties in future outcomes (i.e. risks faced) to measured objectively,
               </li>
               <li>
                 allows pay-offs from options and guarantees to be modelled.
               </li>
               <li>
                 Stochastic models are particularly useful in assessing the impact of financial guarantees.
because such guarantees will lead to a pay-out in some future circumstances and not in others ... which cannot be replicated easily in a deterministic model (where pay-out will definitely occur or definitely not occur, depending on assumptions used.

               </li>
             </ul>
           </li>
           <li>
             Disadvantages
             <ul>
               <li>
                  more difficult (and, thus, expensive) to design, construct and explain. --> greater model risk
               </li>
               <li>
                  Harder to parameterise -> greater parameter risk
               </li>
             </ul>
           </li>
           <li>
             In practice, a combination of deterministic and stochastic models may be used. Stochastic models are often used for more volatile parameters (e.g. investment return), whereas deterministic models are usually used for more stable parameters (e.g. mortality).
           </li>
           <li>
           fluctuations in more volatile variables such as investment returns will tend to have a more significant impact on volatility of profits (and, hence, financial health of company) than fluctuations in more stable variable such as mortality. but, not also true (e.g. profits from term assurance business relatively insensitive to investment experience).
            </li>
         </ul>
       </li>
     </ul>
   </div>
  </div>


  <div class="column middle" >
    <span id="question_2">Assumptions </span>

   <div id="content">
   </div>
  </div>
</div>


</div>


<div id="footer">
</div>

</body>
